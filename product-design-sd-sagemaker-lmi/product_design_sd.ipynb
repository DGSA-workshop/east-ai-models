{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37b3808-8a65-4993-b280-f24bcce6613a",
   "metadata": {},
   "source": [
    "# Deploy product design model on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea203cc5-fa63-4c8e-afe3-450bc6a084a4",
   "metadata": {},
   "source": [
    "本节实验会在 SageMaker 上使用 Large Model Inference（LMI）镜像对 Stable Diffusion 模型进行部署，选用的模型来自于 Civitai（https://civitai.com/models/23893/product-design-minimalism-eddiemauro）\n",
    "该模型在产品设计图生成方面有较好的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df83caa-3338-4d30-980f-9effecefc361",
   "metadata": {},
   "source": [
    "#### Install and upgrade dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed51821-ee6f-4012-a34b-8144d163a257",
   "metadata": {},
   "source": [
    ">注意：执行单元格代码框后，若左侧中括号中的符号为'*'，表示代码正在运行过程中；若为数字，则表示代码已执行完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462304e4-9352-4ebd-b148-cc8926f0245f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip --quiet\n",
    "%pip install sagemaker boto3 awscli --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc0240-b2ce-46db-b4d9-8dcf2f96b9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init sagemaker parameters\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, serializers, deserializers\n",
    "import jinja2\n",
    "from pathlib import Path\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "\n",
    "jinja_env = jinja2.Environment()\n",
    "\n",
    "s3_code_prefix = \"east-ai-models/product-design-sd/accelerate\"\n",
    "\n",
    "print(f\"role: {role}\")\n",
    "print(f\"bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971300-0a18-4fca-a4d8-053053ab4c57",
   "metadata": {},
   "source": [
    "#### Download SD model and upload to S3（该过程大概需要 2 mins）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412fbc5-e781-48b8-9190-402e9fb9a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://d1onssyrnp1eaq.cloudfront.net/productDesignModel.tar.gz\n",
    "!tar -xvzf productDesignModel.tar.gz\n",
    "!rm -rf model-dir/.ipynb_checkpoints\n",
    "!aws s3 sync model-dir/ s3://{bucket}/east-ai-models/product-design-sd/model-dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7d85d-a6e0-4531-b3cc-257b493d24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036c612-6ffe-4d5b-9b8c-5cd3b6714f1b",
   "metadata": {},
   "source": [
    "#### Writing SageMaker LMI code properties and model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c92e7-eeac-47b2-a5d9-64ce37af74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./mymodel/requirements.txt\n",
    "transformers\n",
    "diffusers==0.17.0\n",
    "omegaconf\n",
    "accelerate\n",
    "boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bee1ff-84e5-44c6-a550-55fbe9d598ed",
   "metadata": {},
   "source": [
    "和上一节有些不同，在 LMI 的 serving.properties 中，我们指定了 s3url 参数，表示模型文件在 S3 上。部署时，SageMaker 会使用 s5cmd（高性能 s3 传输工具），从 s3 上直接下载模型文件到本地容器环境中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207a75e-0e62-4bfb-a2ef-058a81b99851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./mymodel/serving.properties\n",
    "engine=Python\n",
    "option.s3url={{s3url}}\n",
    "option.tensor_parallel_degree=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edab035-1032-4127-9222-d5cec6aafa3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = jinja_env.from_string(Path(\"mymodel/serving.properties\").open().read())\n",
    "Path(\"mymodel/serving.properties\").open(\"w\").write(\n",
    "    template.render(s3url=\"s3://{}/east-ai-models/product-design-sd/model-dir/\".format(bucket))\n",
    ")\n",
    "!pygmentize mymodel/serving.properties | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8f1e7-012e-4d97-ba93-7e887543450e",
   "metadata": {},
   "source": [
    "从 s3 上下载的模型文件会存储在 SageMaker 容器环境中临时目录 /tmp 路径下，并将该路径赋值给 model_id，因此我们直接在 get_model() 函数中，从 os.environ[\"model_id\"] 获取模型文件所在的路径，加载模型即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0d28d-1681-4d08-8aa7-956ddbc709e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./mymodel/model.py\n",
    "from djl_python import Input, Output\n",
    "import os\n",
    "import torch\n",
    "from typing import Any, Dict, Tuple\n",
    "import warnings\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "from diffusers import EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, HeunDiscreteScheduler, LMSDiscreteScheduler, KDPM2DiscreteScheduler, KDPM2AncestralDiscreteScheduler,DDIMScheduler\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "from torch import autocast\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "\n",
    "model = None\n",
    "img2img_model = None\n",
    "\n",
    "\n",
    "def get_model(properties):\n",
    "    print(properties)\n",
    "    if \"model_id\" in properties:\n",
    "        model_name = properties[\"model_dir\"]\n",
    "        print(\"=========================model dir: {}============================\".format(model_name))\n",
    "\n",
    "        model_id = properties[\"model_id\"]\n",
    "        os.environ[\"model_id\"] = model_id\n",
    "        djl_list = os.listdir(model_id)\n",
    "        print(\"=========================files in model_id============================\")\n",
    "        print(djl_list)\n",
    "\n",
    "        print(\"=========================files in model_id/vae============================\")\n",
    "        print(os.listdir(model_id+'/vae'))\n",
    "\n",
    "        ml_list = os.listdir('/opt/ml/model')\n",
    "        print(\"=========================files in /opt/ml/model============================\")\n",
    "        print(ml_list)\n",
    "    \n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\n",
    "    model = StableDiffusionPipeline.from_pretrained(os.environ[\"model_id\"])\n",
    "    model = model.to(\"cuda\")\n",
    "    img2img_model = StableDiffusionImg2ImgPipeline.from_pretrained(os.environ[\"model_id\"])\n",
    "    img2img_model = img2img_model.to(\"cuda\")\n",
    "    return model, img2img_model\n",
    "\n",
    "\n",
    "def handle(inputs: Input) -> None:\n",
    "    global model, img2img_model\n",
    "    print(model)\n",
    "    print(img2img_model)\n",
    "    print(\"print inputs: \" + str(inputs) + '.'*20)\n",
    "    \n",
    "    if not model:\n",
    "        model, img2img_model = get_model(inputs.get_properties())\n",
    "    \n",
    "    samplers = {\n",
    "        \"euler_a\": EulerAncestralDiscreteScheduler,\n",
    "        \"eular\": EulerDiscreteScheduler,\n",
    "        \"heun\": HeunDiscreteScheduler,\n",
    "        \"lms\": LMSDiscreteScheduler,\n",
    "        \"dpm2\": KDPM2DiscreteScheduler,\n",
    "        \"dpm2_a\": KDPM2AncestralDiscreteScheduler,\n",
    "        \"ddim\": DDIMScheduler\n",
    "    }\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "    \n",
    "    input_data = inputs.get_as_json()\n",
    "    \n",
    "    if 'input_image' in input_data:\n",
    "        if input_data['input_image'].startswith('s3://'):\n",
    "            dir_lst = input_data['input_image'].split('/')\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_response_object = s3_client.get_object(Bucket=dir_lst[2], Key='/'.join(dir_lst[3:]))\n",
    "            img_bytes = s3_response_object['Body'].read()\n",
    "            init_img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "            init_img = init_img.resize((input_data['width'], input_data['height']))\n",
    "        else:\n",
    "            input_image = input_data['input_image']\n",
    "            init_img = Image.open(io.BytesIO(base64.b64decode(input_image))).convert(\"RGB\")\n",
    "            init_img = init_img.resize((input_data['width'], input_data['height']))\n",
    "        if input_data['seed'] == -1:\n",
    "            generator = torch.Generator(device='cuda').manual_seed(random.randint(1, 10000000))\n",
    "        else:\n",
    "            generator = torch.Generator(device='cuda').manual_seed(input_data['seed'])\n",
    "        with autocast('cuda'):\n",
    "            img2img_model.scheduler = samplers[input_data[\"sampler\"]].from_config(img2img_model.scheduler.config)\n",
    "            images = img2img_model(\n",
    "                input_data['prompt'],\n",
    "                image=init_img,\n",
    "                negative_prompt=input_data['negative_prompt'],\n",
    "                num_inference_steps=input_data['steps'],\n",
    "                num_images_per_prompt=input_data['count'],\n",
    "                generator=generator).images\n",
    "        print(\"Prediction: \" + str(images) + '.'*20)\n",
    "    \n",
    "    else:\n",
    "        if input_data['seed'] == -1:\n",
    "            generator = torch.Generator(device='cuda').manual_seed(random.randint(1, 10000000))\n",
    "        else:\n",
    "            generator = torch.Generator(device='cuda').manual_seed(input_data['seed'])\n",
    "        with autocast('cuda'):\n",
    "            model.scheduler = samplers[input_data[\"sampler\"]].from_config(model.scheduler.config)\n",
    "            images = model(\n",
    "                input_data['prompt'],\n",
    "                input_data[\"height\"],\n",
    "                input_data[\"width\"],\n",
    "                negative_prompt=input_data['negative_prompt'],\n",
    "                num_inference_steps=input_data['steps'],\n",
    "                num_images_per_prompt=input_data['count'],\n",
    "                generator=generator).images\n",
    "        print(\"Prediction: \" + str(images) + '.'*20)\n",
    "    \n",
    "    res = {'images': [], 'images_path': []}\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    dir_lst = input_data['output_image_dir'].split('/')\n",
    "    s3_bucket = dir_lst[2]\n",
    "    for image in images:\n",
    "        byteImgIO = io.BytesIO()\n",
    "        image.save(byteImgIO, \"WEBP\")\n",
    "        byteImgIO.seek(0)\n",
    "        byteImg = byteImgIO.read()\n",
    "        imgstr = base64.b64encode(byteImg).decode('ascii')\n",
    "        res['images'].append(imgstr)\n",
    "        \n",
    "        img_id = uuid.uuid4().hex\n",
    "        s3_object_key = '/'.join(dir_lst[3:]) + img_id + '.webp'\n",
    "        s3_resource.Bucket(s3_bucket).put_object(Key=s3_object_key, Body=byteImg, ContentType='image/webp')\n",
    "        image_output = 's3://{}/{}'.format(s3_bucket, s3_object_key)\n",
    "        res['images_path'].append(image_output)\n",
    "\n",
    "    return Output().add(json.dumps(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4317a1-9aef-470e-b36e-d8b01492158f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compress code and upload to S3\n",
    "!rm -f model.tar.gz\n",
    "!rm -rf mymodel/.ipynb_checkpoints\n",
    "!tar czvf model.tar.gz -C mymodel .\n",
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b6e9eb-62b2-4816-9086-c65645ae4575",
   "metadata": {},
   "source": [
    "#### Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16a983-8438-41e8-9f61-e617c581eab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve SageMaker LMI container image URI\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\", region=region, version=\"0.23.0\"\n",
    ")\n",
    "\n",
    "\n",
    "print(image_uri)\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=s3_code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866d32c-68e5-48a3-adea-dd2f344214ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"  # \"ml.g5.2xlarge\" - #single GPU. really need one GPU for this since tensor split is '1'\n",
    "\n",
    "endpoint_name = \"product-design-sd\"\n",
    "\n",
    "print(\"模型部署过程大约需要 7~8 分钟，请等待\" + \".\"*20)\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=900,\n",
    ")\n",
    "\n",
    "print(\"模型部署已完成，可以继续执行后续步骤\" + \".\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38dc90-e3e1-4d6c-9375-104d120067aa",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b0b67-4384-4947-9d56-a9c7d2aeca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa94ab-6c16-4e73-b819-c09474a63d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "\n",
    "def predict_fn(predictor, inputs):\n",
    "    if 'input_image' in inputs:\n",
    "        if inputs['input_image'].startswith('s3://'):\n",
    "            response = predictor.predict(inputs)\n",
    "        else:\n",
    "            img = Image.open(inputs['input_image'])\n",
    "            byteImgIO = io.BytesIO()\n",
    "            img.save(byteImgIO, \"PNG\")\n",
    "            byteImgIO.seek(0)\n",
    "            byteImg = byteImgIO.read()\n",
    "            imgstr = base64.b64encode(byteImg).decode('ascii')\n",
    "            inputs['input_image'] = imgstr\n",
    "            response = predictor.predict(inputs)\n",
    "    else:\n",
    "        response = predictor.predict(inputs)\n",
    "    for image in response['images']:\n",
    "        dataBytesIO = io.BytesIO(base64.b64decode(image))\n",
    "        image = Image.open(dataBytesIO)\n",
    "        display(image)\n",
    "    for path in response['images_path']:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bf834-9570-43bf-8594-9ae9e683040e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"prompt\": \"3D product render, futuristic tent, finely detailed, purism, ue 5, a computer rendering, minimalism, octane render, 4k\",\n",
    "    \"negative_prompt\": \"EasyNegative, (worst quality:2), (low quality:2), (normal quality:2), lowres, ((monochrome)), ((grayscale)), cropped, text, jpeg artifacts, signature, watermark, username, sketch, cartoon, drawing, anime, duplicate, blurry, semi-realistic, out of frame, ugly, deformed\",\n",
    "    \"steps\": 30,\n",
    "    \"sampler\": \"dpm2_a\",\n",
    "    \"seed\": -1,\n",
    "    \"height\": 512,\n",
    "    \"width\": 512,\n",
    "    \"count\": 1,\n",
    "    \"output_image_dir\": \"s3://{}/product-design-output/\".format(bucket)\n",
    "}\n",
    "\n",
    "predict_fn(predictor, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61951d0d-bdc1-434d-90c3-59ae54073718",
   "metadata": {},
   "source": [
    "> 注意：保存推理生成的图片地址，如：“s3://sagemaker-us-east-1-349184662326/product-design-output/ee211a41297344f5b5de636bf093def8.webp”。在下一节 notebook（grounded_sam_inpaint_sagemaker.ipynb）中会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b191d89-16fa-40f5-970b-573485169b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
